# Server floor fabric side
# Outward facing
# oversight for both

Angel and Jen
Execution and Delivery
Plan the network

GNT - tigerlilly
Make sure network is in the gray box
Don't put chip in locations where there is not enough networking

Fabric 
Superblock
Skeleton
Networking Racks
Fabric intent pool

Shelby
Projects to install on the network floor

Fabric intent pool
Machine side next to machine
Network planning
Cluster network is planned on the same horizon as power

FBR - boundary
South - cluster
North - planned by 

CLCS

Ghost - RS
Net RS

BIT side of 
Network side of the capacity
Curate network
B4

Inten

GMS team
12 month - only order twelve

BITS and ports - superblock for so many machines
GGN Netsoft

By Product 
A-Z points
Flows

Cluster house
Network flows piping inbetween houses

Campus talk to each other

Machines and BITs are ordered indepedents

Are they all going to each other
Matt Johnson and Topal

# this is a good article on 
https://calvinyluo.com/2022/08/26/diffusion-tutorial.html
https://lilianweng.github.io/posts/2018-08-12-vae/
# go/pixelml

# RAG

Limitations on LLM
- staleness - old data
- hallucination - non-sensical
- attribution - what is the source of the answer
- customization - generic responses

Retrieve related documents from input
This becomes the Context for the model


# R
1.
Control image generation with text

Iron Man transform into different things
Lora and Dreambooth
How to preserve certain aspect of images
identify identy and style
Can tell what they are
How to describe what Robert Downy Jr

Preserve a synthetic 
Adapt a diffusion model
Consistent

Dreambooth

Fine tune a model
Retrain the model for something

Take a bunch of pictures of a person
Hard or overfitting

Specialized to become this person

Picture of Robert Downy Junior

Preserve someone

4G models

A lot of model variance

Dreambooth model

How to do iron man suite

Very expensive and intensive over time

How to hook models together

Plug a little attachment to it

Attachment to modify weights in the model

Store the information

LORA are 

Train a bunch of Lora, work for the same
models in the same family

Stable diffusion XL

Latent space is destroyed 

Same thing Flux

Lora - save into attachment

Break into to matrix A B

output lower rank mati

L2 output L1 + Lora low rank cross product

Dora Lora

sd Xl

Flux

Lora

Denoisig Diffusion Probabilistic Models
https://arxiv.org/pdf/2006.11239

DDPM: https://arxiv.org/pdf/2006.11239
SDXL: https://arxiv.org/pdf/2307.01952

For everything time step
Keep increasing the noise until 
Image is destroyed

Diffusion in conjuction of NN

https://arxiv.org/pdf/2407.01392
Diffusion forcing
Good at explaining visually

Network transfer for coding to research

Strong research presence
- Research 
- Academia 
- Show that you can do research
- Publish
- Novel algorithm

Infra to do modelling
Work really hard to get that

Niche company or position
Can't be solved by anything else but 

Organization - 

Uncompromising about opportunities

Hyper network

Advisor for the company

Researchers that say yes

Help can I help with a paper

Read research work starting point

Suggestion cool expansion

Idea - build that 

Leverage.

# simple framework for constractive learning
# emerging properties in self-supervised vision transformers

# dl stanford
http://ufldl.stanford.edu/tutorial/

# rank
https://en.wikipedia.org/wiki/Okapi_BM25

# Constrastive learning:
https://lilianweng.github.io/posts/2021-05-31-contrastive/

# google visual
https://g3doc.corp.google.com/vision/visualsearch/g3doc/glossary.md?cl=head

Nice glossary and links to papers

# google deep learning crash course
https://g3doc.corp.google.com/company/teams/ads-ml/dlcc/part-3/other_architectures.md?cl=head

# good explanation of fast vs faster vs yolo
https://stackoverflow.com/questions/44255411/which-is-best-for-object-localization-among-r-cnn-fast-r-cnn-faster-r-cnn-and

# conformer
https://arxiv.org/pdf/2005.08100

# squeezeformer
https://arxiv.org/pdf/2206.00888

https://machinelearningmastery.com/brief-introduction-to-diffusion-models-for-image-generation/#:~:text=Image%20generation%20is%20achieved%20by,the%20form%20of%20embedding%20vectors.

https://eugeneyan.com/writing/text-to-image/


speculative decoding

inception
resnet model

https://www.amazon.com/Machine-Learning-System-Design-Interview/dp/1736049127

Probably not state of the art model
Good understanding of the real reployment
Not implementing GenAI
Recommendation
Ranking

ML Engineering ML Infra
Can debug the models
and can monitor the models and maintain the models

ML Scientist
How to improve models

Applied Scientist
Most roles

Not completely not a Research Scientit

# resnet

1. https://viso.ai/deep-learning/resnet-residual-neural-network/
   1. Stacking layers can enrich the model
   2. deeper network can degrade
   3. accuracy may get saturated
   4. slowly degrade after a point
   5. Not a result of overfitting
   6. From initialization of the network
   7. Optimization function
   8. Problem of vanishing gradients
2. Skip connections
   1. Alternate shortcut for the gradient to pass through
   2. Allow the model to lean an identity function
      1. What does this mean?
3. Mark R-CNN - detects objects in an image
   1. Generate high-quality segmentation masks
4. ROI Pooling layer
   1. Downsamples feature maps by summarizing the presence of features in patches of the feature map
5. R-CNN Region CNN
   1. Extract region proposals (2k)
   2. Compute CNN features
   3. Classify regions
6. Fast RCNN
   1. Has two stages: RPN
   2. ROI Pool from each candidate box
   3. classification and bounding box regression
   4. ROI Pool extracts a small feature map from each ROI in detection considering various aspect ratios
   5. Make region proposals on the feature map
   6. System performs convolution operation only once per image
7. Mask RCNN
   1. Semantic segmentation
      1. Classifies each pixel into a fixed set of categories
      2. Instance segmentation
8. Mask RCNN
   1. Output of Faster R-CNN
      1. Candidate object
      2. Class label
      3. bounding box offset
   2. Mask RCEE
      1. also outputs the object mas
      2. k

RCNN
Select search
Simple segmentation
Graph based segmentation


# ml

# boosting vs bagging
https://blog.mlreview.com/gradient-boosting-from-scratch-1e317ae4587d


# converting 
## conda

conda init bash

copy from c:\Users...\.bash_profile to
~/bin/conda_stuff


conda info --envs
conda env list

conda remove -n <envname> --all -y
conda env remove -n <envname> -y

conda clean -a # remove tarballs

conda rename -p <path> newname

Install with multiple libraries
conda create -n <name> anaconda

## David Reed

### Success Hacks
1. Be prepared
2. Attend every class
3. Participate in class
4. Attempt all assignments
5. Advocate for yourself
6. Keep goal
7. Consistency is key


### Support features
1. Post class videos
2. Coaching sessions on Wed
3. Discord
4. TAs
5. Use academic support (SSAs)
6. Support tickets

# Multimodal training
Diffusion model 
- more graceful
- not for overfitting

Overfit
- generalize and specialized
- control depth and width
- Resnet, dropout
- Top down
- Residual connection
- Not introducing to penalize
  - whole network
- stop co-adaptation
  - Preventing one part doing the same as another task 

- Overfit and generalize every level

2d modality
one modality may not map with another modality

k-near neighbor

1. Shop talk
2. Noise is helping to regenerate them

# papers to read

https://blog.mlreview.com/gradient-boosting-from-scratch-1e317ae4587d
https://blog.mlreview.com/gradient-boosting-from-scratch-1e317ae4587d

https://github.com/hurshd0/must-read-papers-for-ml
https://github.com/aimerou/awesome-ai-papers
https://github.com/terryum/awesome-deep-learning-papers
https://github.com/elicit/machine-learning-list
https://github.com/thunlp/RCPapers
https://github.com/dair-ai/ML-Papers-of-the-Week
https://github.com/daturkel/learning-papers

https://docs.google.com/document/d/1nd4-CsavBD1hmvdyokc5OYiK7pThJttrCphuReJeO7k/edit?tab=t.0

The Kernel Trick in Support Vector Classification | by Drew Wilimitis | Towards Data Science
https://towardsdatascience.com/the-kernel-trick-c98cdbcaeb3f
Kernel 

SVM
Tabular data can get away with decision trees

SVM basically transform the data into kernels then you can do vector stuff on them like
SVM  - good for images and audio

But NN nowadays for this kind of data
---
